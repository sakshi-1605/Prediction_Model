{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pdb\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "with zipfile.ZipFile('training_setB.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('training_setB')\n",
    "files = glob.glob('training_setB/training_setB/*.psv')\n",
    "\n",
    "df_list = []\n",
    "for ind, f in enumerate(files):\n",
    "    # print(f)\n",
    "    # print(f.split('/')[1])\n",
    "    # print(f.split('/')[2])\n",
    "    # print(f.split('/')[2].split('.')[0])\n",
    "    patient_id = f.split('/')[2].split('.')[0]\n",
    "    # patient_id = f.split('/')[1].split('.')[0]\n",
    "\n",
    "    df = pd.read_csv(f, sep='|')\n",
    "    df = df.assign(patient=patient_id)\n",
    "    df.loc[df[df['SepsisLabel'] == 1].head(6).index.values, 'SepsisLabel'] = 1\n",
    "\n",
    "    if ind % 1000 == 0:\n",
    "        print(ind)\n",
    "    df_list.append(df)\n",
    "\n",
    "    # break\n",
    "\n",
    "# Save in pickle file\n",
    "df = pd.concat(df_list)\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_pickle('combined.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdb\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if os.path.exists('feats'):\n",
    "        shutil.rmtree('feats')\n",
    "    os.makedirs('feats')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('combined.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_path = 'combined.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage Missing:')\n",
    "print(df.isna().sum()/len(df))\n",
    "cols_to_drop = ['Unit2', 'ICULOS']\n",
    "df = df.drop(cols_to_drop, axis=1)\n",
    "cols_cont = ['HR', 'MAP', 'O2Sat', 'SBP', 'Resp']\n",
    "cols_to_bin = ['Unit1', 'Gender', 'HospAdmTime', 'Age', 'DBP', 'Temp', 'Glucose', 'Potassium', 'Hct', 'FiO2', 'Hgb', 'pH', 'BUN', 'WBC', 'Magnesium', 'Creatinine', 'Platelets', 'Calcium', 'PaCO2', 'BaseExcess', 'Chloride', 'HCO3', 'Phosphate', 'EtCO2', 'SaO2', 'PTT', 'Lactate', 'AST', 'Alkalinephos', 'Bilirubin_total', 'TroponinI', 'Fibrinogen', 'Bilirubin_direct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_training_data = df['patient'].unique()\n",
    "np.random.shuffle(patients_training_data)\n",
    "patients_training_data = patients_training_data[0:-6000]\n",
    "\n",
    "df_mean_std = df[df['patient'].isin(patients_training_data)].describe().loc[['mean', 'std']]\n",
    "df_mean_std.to_pickle('mean_std_scaling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of positive training examples:')\n",
    "sum(df[df['patient'].isin(patients_training_data)]['SepsisLabel']==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through each patient\n",
    "save_count = 0\n",
    "windowed_df_list = []\n",
    "grouped_by_patient = df.groupby('patient')\n",
    "for patient, group in grouped_by_patient:\n",
    "    #print(patient)\n",
    "    group = group.reset_index(drop=True)\n",
    "\n",
    "    #backfill any missing values\n",
    "    group = group.assign(HR=group['HR'].fillna(method='bfill').fillna(method='ffill'))\n",
    "    group = group.assign(MAP=group['MAP'].fillna(method='bfill').fillna(method='ffill'))\n",
    "    group = group.assign(O2Sat=group['O2Sat'].fillna(method='bfill').fillna(method='ffill'))\n",
    "    group = group.assign(SBP=group['SBP'].fillna(method='bfill').fillna(method='ffill'))\n",
    "    group = group.assign(Resp=group['Resp'].fillna(method='bfill').fillna(method='ffill'))\n",
    "\n",
    "    group = group.assign(HR=(group['HR']-df_mean_std['HR']['mean'])/(df_mean_std['HR']['std']))\n",
    "    group = group.assign(MAP=(group['MAP']-df_mean_std['MAP']['mean'])/(df_mean_std['MAP']['std']))\n",
    "    group = group.assign(O2Sat=(group['O2Sat']-df_mean_std['O2Sat']['mean'])/(df_mean_std['O2Sat']['std']))\n",
    "    group = group.assign(SBP=(group['SBP']-df_mean_std['SBP']['mean'])/(df_mean_std['SBP']['std']))\n",
    "    group = group.assign(Resp=(group['Resp']-df_mean_std['Resp']['mean'])/(df_mean_std['Resp']['std']))\n",
    "\n",
    "    #generate windows of 10 hours\n",
    "    windowed_data = []\n",
    "    N = len(group)\n",
    "    win_len = 10\n",
    "    pred_len = 1\n",
    "    i = 0\n",
    "    while(i+win_len+pred_len <= N):\n",
    "        tmp_data = group.iloc[i:i+win_len]\n",
    "        tmp_label = group.iloc[i+win_len:i+win_len+pred_len]\n",
    "        tmp_label = int(any(tmp_label['SepsisLabel']))\n",
    "        tmp_patient = patient\n",
    "        i = i+1\n",
    "        X_cont = tmp_data[cols_cont]\n",
    "        X_cont = X_cont.values\n",
    "        if np.isnan(X_cont).any(): continue\n",
    "        X_binned_dict = {}\n",
    "        for col_to_bin in cols_to_bin:\n",
    "            tmp_val = tmp_data[col_to_bin].median()\n",
    "            if col_to_bin not in ['Gender', 'Unit1']:\n",
    "                tmp_val = (tmp_val-df_mean_std[col_to_bin]['mean'])/df_mean_std[col_to_bin]['std']\n",
    "\n",
    "            X_binned_dict[col_to_bin] = tmp_val\n",
    "        tmp_dict = X_binned_dict\n",
    "        tmp_dict['X_cont'] = X_cont\n",
    "        tmp_dict['label'] = tmp_label\n",
    "        tmp_dict['patient'] = tmp_patient\n",
    "        windowed_data.append(tmp_dict)\n",
    "    windowed_data_df = pd.DataFrame(windowed_data)\n",
    "    windowed_df_list.append(windowed_data_df)D\n",
    "    patient_id_numeric = ''.join(filter(str.isdigit, patient))\n",
    "    if patient_id_numeric:\n",
    "        patient_id_int = int(patient_id_numeric[-5:]) \n",
    "    else:\n",
    "        patient_id_int = 0\n",
    "\n",
    "    if (patient_id_int % 500) == 0:\n",
    "        print('patient %i' % patient_id_int)\n",
    "        windowed_df = pd.concat(windowed_df_list).reset_index(drop=True)\n",
    "        train = windowed_df[windowed_df['patient'].isin(patients_training_data)].drop('patient', axis=1)\n",
    "        test = windowed_df[~windowed_df['patient'].isin(patients_training_data)].drop('patient', axis=1)\n",
    "\n",
    "        train.to_pickle('feats/train_%i.pkl' % save_count)\n",
    "        test.to_pickle('feats/test_%i.pkl' % save_count)\n",
    "\n",
    "        windowed_df_list = []\n",
    "        save_count = save_count + 1\n",
    "\n",
    "if len(windowed_df_list) > 0:\n",
    "    windowed_df = pd.concat(windowed_df_list).reset_index(drop=True)\n",
    "    train = windowed_df[windowed_df['patient'].isin(patients_training_data)].drop('patient', axis=1)\n",
    "    test = windowed_df[~windowed_df['patient'].isin(patients_training_data)].drop('patient', axis=1)\n",
    "\n",
    "    train.to_pickle('feats/train_%i.pkl' % save_count)\n",
    "    test.to_pickle('feats/test_%i.pkl' % save_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pdb\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if os.path.exists('plots'):\n",
    "        shutil.rmtree('plots')\n",
    "    os.makedirs('plots')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = glob.glob('feats/train_*.pkl')\n",
    "train = []\n",
    "for train_file in train_files:\n",
    "    train.append(pd.read_pickle(train_file))\n",
    "\n",
    "train = pd.concat(train)\n",
    "test_files = glob.glob('feats/test_*.pkl')\n",
    "test = []\n",
    "for test_file in test_files:\n",
    "    test.append(pd.read_pickle(test_file))\n",
    "\n",
    "test = pd.concat(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_train = train.select_dtypes(include=[np.number])\n",
    "print(numeric_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = numeric_train.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "plt.figure(figsize=(16,9))\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/heatmap.png', dpi=250)\n",
    "plt.show()\n",
    "train.to_pickle('train.pkl')\n",
    "test.to_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import TimeDistributed, Bidirectional, BatchNormalization, Dropout, Input, Add, Masking\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from keras import Model\n",
    "import pdb\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import glob\n",
    "import sys\n",
    "from sklearn.metrics import auc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "INPUT_SEQ_LEN_MODEL1 = 10\n",
    "INPUT_NUM_CH_MODEL1 = 5\n",
    "INPUT_FEATS_MODEL2 = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc(predictions, true, filename):\n",
    "    predictions = predictions.flatten()\n",
    "    true = true.flatten()\n",
    "\n",
    "    thresh_vals = np.linspace(np.min(predictions), np.max(predictions), 50)\n",
    "    results = []\n",
    "    for thresh in thresh_vals:\n",
    "        tmp_predictions = (predictions > thresh).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(true, tmp_predictions).ravel()\n",
    "        tpr = tp/(tp+fn)\n",
    "        fpr = fp/(tn+fp)\n",
    "        acc = (tp+tn)/(tn+fp+fn+tp)\n",
    "\n",
    "        tmp_dict = {'acc': acc, 'tpr': tpr, 'fpr': fpr, 'thresh': thresh}\n",
    "        results.append(tmp_dict)\n",
    "\n",
    "    results = pd.DataFrame(results)\n",
    "    results = results.sort_values(by='thresh', ascending=False)\n",
    "\n",
    "    #calculate the AUC\n",
    "    AUC = auc(results['fpr'].values, results['tpr'].values)\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(results['fpr'], results['tpr'], '*-')\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title('ROC\\nAUC=%.2f' % AUC)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/ROC_%s.png' % filename, dpi=250)\n",
    "    plt.show()\n",
    "\n",
    "    results = results.sort_values(by='acc', ascending=False)\n",
    "    final_thresh = results.head(1)['thresh'].values[0]\n",
    "\n",
    "    return results, final_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('train.pkl').reset_index(drop=True)\n",
    "N = len(train)\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "val = train[:int(N*0.2)]\n",
    "train = train[int(N*0.2):]\n",
    "\n",
    "y_train = np.asarray(list(train['label']))\n",
    "y_train = to_categorical(y_train)\n",
    "X_train_cont = np.asarray(list(train['X_cont'].values))\n",
    "X_train_cat = train.drop(['X_cont', 'label'], axis=1)\n",
    "X_train_cat[X_train_cat.isna()] = np.pi\n",
    "X_train_cat = np.asarray(list(X_train_cat.values))\n",
    "\n",
    "y_val = np.asarray(list(val['label']))\n",
    "y_val = to_categorical(y_val)\n",
    "X_val_cont = np.asarray(list(val['X_cont'].values))\n",
    "X_val_cat = val.drop(['X_cont', 'label'], axis=1)\n",
    "\n",
    "#replace NaN with pi\n",
    "X_val_cat[X_val_cat.isna()] = np.pi\n",
    "X_val_cat = np.asarray(list(X_val_cat.values))\n",
    "\n",
    "#test data\n",
    "test = pd.read_pickle('test.pkl')\n",
    "y_test = np.asarray(list(test['label']))\n",
    "y_test = to_categorical(y_test)\n",
    "X_test_cont = np.asarray(list(test['X_cont'].values))\n",
    "X_test_cat = test.drop(['X_cont', 'label'], axis=1)\n",
    "\n",
    "X_test_cat[X_test_cat.isna()] = np.pi\n",
    "X_test_cat = np.asarray(list(X_test_cat.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_0 = np.sum(y_train[:,1].astype(int)==0)\n",
    "count_class_1 = np.sum(y_train[:, 1].astype(int) == 1)\n",
    "max_class_counts = np.max((count_class_0, count_class_1))\n",
    "class_weights = {0: max_class_counts/count_class_0, 1: max_class_counts/count_class_1}\n",
    "print('class weights -- no sepsis: {}, sepsis: {}'.format(class_weights[0], class_weights[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = Input(shape=(INPUT_SEQ_LEN_MODEL1, INPUT_NUM_CH_MODEL1))\n",
    "model1 = Bidirectional(LSTM(100, kernel_regularizer=l2(0.001), return_sequences=True))(input1)\n",
    "model1 = Bidirectional(LSTM(75, kernel_regularizer=l2(0.001)))(model1)\n",
    "model1 = Dense(35, kernel_regularizer=l2(0.001), activation='relu')(model1)\n",
    "model1 = LayerNormalization()(model1)\n",
    "model1 = Dense(15, kernel_regularizer=l2(0.001), activation='relu')(model1)\n",
    "model1 = LayerNormalization()(model1)\n",
    "\n",
    "input2 = Input(shape=(INPUT_FEATS_MODEL2,))\n",
    "model2 = Masking(mask_value=np.pi)(input2)\n",
    "model2 = Dense(30, kernel_regularizer=l2(0.001), activation='relu')(model2)\n",
    "model2 = LayerNormalization()(model2)\n",
    "model2 = Dense(15, kernel_regularizer=l2(0.001), activation='relu')(model2)\n",
    "model2 = LayerNormalization()(model2)\n",
    "\n",
    "model_add = Add()([model1, model2])\n",
    "output = Dense(2, kernel_regularizer=l2(0.001), activation='softmax')(model_add)\n",
    "\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('model.keras', monitor='val_loss', verbose=1, save_best_only=True, mode='auto', save_freq='epoch')\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=4)\n",
    "history = model.fit([X_train_cont, X_train_cat],\n",
    "                    y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=50,\n",
    "                    validation_data=([X_val_cont, X_val_cat], y_val),\n",
    "                    callbacks=[earlystop, checkpoint],\n",
    "                    class_weight=class_weights,\n",
    "                    verbose=1)\n",
    "\n",
    "#save the history\n",
    "pickle.dump(history, open('history.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(history.history['loss'], '*-')\n",
    "plt.plot(history.history['val_loss'], '*-')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/loss.png', dpi=250)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([X_val_cont, X_val_cat])\n",
    "\n",
    "results_df, thresh_final = roc(predictions[:,1].flatten(), y_val[:,1].flatten(), 'val')\n",
    "results_df = results_df.sort_values(by='fpr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([X_test_cont, X_test_cat])\n",
    "\n",
    "results_df, thresh_final = roc(predictions[:,1].flatten(), y_test[:,1].flatten(), 'test')\n",
    "results_df = results_df.sort_values(by='fpr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate performance statistics without Epic seismometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "predictions_val = model.predict([X_val_cont, X_val_cat])\n",
    "y_pred_val = (predictions_val[:, 1] > thresh_final).astype(int)  \n",
    "y_true_val = y_val[:, 1].astype(int)\n",
    "\n",
    "predictions_test = model.predict([X_test_cont, X_test_cat])\n",
    "y_pred_test = (predictions_test[:, 1] > thresh_final).astype(int)\n",
    "y_true_test = y_test[:, 1].astype(int)\n",
    "\n",
    "precision_val = precision_score(y_true_val, y_pred_val)\n",
    "recall_val = recall_score(y_true_val, y_pred_val)\n",
    "f1_val = f1_score(y_true_val, y_pred_val)\n",
    "classification_report_val = classification_report(y_true_val, y_pred_val)\n",
    "\n",
    "precision_test = precision_score(y_true_test, y_pred_test)\n",
    "recall_test = recall_score(y_true_test, y_pred_test)\n",
    "f1_test = f1_score(y_true_test, y_pred_test)\n",
    "classification_report_test = classification_report(y_true_test, y_pred_test)\n",
    "\n",
    "print(\"Validation Set Performance:\")\n",
    "print(f\"Precision: {precision_val:.4f}\")\n",
    "print(f\"Recall: {recall_val:.4f}\")\n",
    "print(f\"F1 Score: {f1_val:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_val)\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(f\"Precision: {precision_test:.4f}\")\n",
    "print(f\"Recall: {recall_test:.4f}\")\n",
    "print(f\"F1 Score: {f1_test:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_test)\n",
    "\n",
    "with open('classification_report_val.txt', 'w') as val_report:\n",
    "    val_report.write(\"Validation Set Classification Report\\n\")\n",
    "    val_report.write(classification_report_val)\n",
    "\n",
    "with open('classification_report_test.txt', 'w') as test_report:\n",
    "    test_report.write(\"Test Set Classification Report\\n\")\n",
    "    test_report.write(classification_report_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate performance statistics with Epic seismometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "if not os.path.exists(\"seismometer\"):\n",
    "    print(\"Cloning Seismometer repository...\")\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/epic-open-source/seismometer.git\"])\n",
    "\n",
    "print(\"Installing required dependencies...\")\n",
    "subprocess.run([\"pip\", \"install\", \"-r\", \"seismometer/requirements.txt\"])\n",
    "\n",
    "print(\"Generating predictions...\")\n",
    "test_file = \"test.pkl\" \n",
    "if not os.path.exists(test_file):\n",
    "    raise FileNotFoundError(f\"{test_file} not found. Ensure your preprocessing steps are correct.\")\n",
    "\n",
    "test_data = pd.read_pickle(test_file)\n",
    "X_test = test_data['X_cont']\n",
    "y_test = test_data['label']\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"model.keras\")  \n",
    "predictions = model.predict([pd.DataFrame(X_test.values.tolist())])\n",
    "y_pred = (predictions[:, 1] > 0.5).astype(int)  \n",
    "\n",
    "output_file = \"seismometer/predictions.csv\"\n",
    "predictions_df = pd.DataFrame({\n",
    "    \"PatientID\": test_data['patient'], \n",
    "    \"Time\": range(len(test_data)),  \n",
    "    \"SepsisLabel\": y_pred\n",
    "})\n",
    "predictions_df.to_csv(output_file, index=False)\n",
    "print(f\"Predictions saved to {output_file}\")\n",
    "\n",
    "print(\"Running Seismometer evaluation...\")\n",
    "labels_file = \"seismometer/labels.csv\" \n",
    "\n",
    "labels_df = pd.DataFrame({\n",
    "    \"PatientID\": test_data['patient'],  \n",
    "    \"Time\": range(len(test_data)),  \n",
    "    \"SepsisLabel\": y_test\n",
    "})\n",
    "labels_df.to_csv(labels_file, index=False)\n",
    "print(f\"Labels saved to {labels_file}\")\n",
    "\n",
    "evaluator_script = \"seismometer/evaluator.py\"\n",
    "subprocess.run([\"python\", evaluator_script, \"--predictions\", output_file, \"--labels\", labels_file])\n",
    "\n",
    "print(\"Calculating additional metrics...\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "roc_auc = roc_auc_score(y_test, predictions[:, 1])\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
